# Product Requirements Document (PRD)
**项目名称:** Hacker News Chinese  
**版本:** v0.1 (MVP)  
**状态:** Draft  
**技术栈:** React + FastAPI + Supabase  

---

## 1. 项目背景与目标 (Background & Objectives)

### 1.1 背景
Hacker News (HN) 是全球高质量技术信息的聚集地，但存在两个主要痛点：
1. **语言门槛:** 全英文内容阻碍了中文母语者的快速阅读。
2. **信息过载:** 每天产生大量内容，用户难以在点击链接前判断文章价值，且难以快速提取核心观点。

### 1.2 目标
构建一个 **AI 驱动的技术资讯聚合平台**，通过自动化流程获取 HN 热门文章，利用 LLM 进行中文翻译与深度总结，并提供基于文章内容的问答互动功能，帮助用户高效获取技术资讯。

### 1.3 核心价值 (Value Proposition)
* **无障碍阅读:** 中文标题与摘要。
* **高效获取:** AI 提炼的核心观点与优缺点分析。
* **深度交互:** 针对特定文章及全站内容的 RAG (检索增强生成) 问答。

---

## 2. 用户流程 (User Flow)

1. **浏览列表:** 用户进入首页，浏览“当前热门”文章列表（显示中文标题 + 简短摘要 + 热度）。
2. **查看详情:** 用户点击感兴趣的文章，查看 AI 生成的详细分析报告（背景、核心要点列表、技术细节）。
3. **原文跳转:** 用户可点击链接跳转至英文原文。
4. **AI 对话 (单篇):** 用户对文章内容有疑问，在侧边/底部对话框提问，AI 基于文章正文进行回答。
5. **全站对话 (Global):** 用户在首页通过全局对话框询问（如“最近有哪些关于 Rust 的文章？”），AI 基于全站历史数据进行检索和总结。
6. **历史回溯:** 用户可在文章详情页查看该文章下的历史对话列表，点击可加载旧的对话上下文并继续提问。

---

## 3. 功能需求 (Functional Requirements)

### 3.1 后端与数据处理 (Backend - FastAPI)

| ID | 功能模块 | 详细描述 | 优先级 |
|:---|:---|:---|:---|
| B1 | **定时任务调度** | 系统每隔固定时间（如 30 分钟）自动触发数据更新流程。 | P0 |
| B2 | **HN 数据获取** | 调用 HN API 获取 Top Stories ID 列表。**严格过滤数据类型，仅处理 `type="story"` 的条目**（剔除 `job`, `poll` 等）。在此基础上筛选 Score > 100 或 Top 30 的文章。 | P0 |
| B3 | **内容提取/爬取** | 1. **普通 Story:** 根据 `url` 爬取网页正文 (Jina)。<br>2. **Ask HN/Show HN:** 此类文章通常包含 `text` 字段。系统需同时保留 `url` 指向的内容（若有）和 `text` 中的作者自述。 | P0 |
| B4 | **LLM 处理管道** | 将以下三部分信息组合作为 LLM 的输入上下文：<br>1. **Title**: 原文标题。<br>2. **Text**: HN 帖子原本的文本（HTML转纯文本）。<br>3. **Scraped Content**: 从 URL 抓取的外部网页正文。<br><br>LLM 需综合这些信息进行翻译、总结和分析。 | P0 |
| B5 | **数据持久化** | 将原始元数据、爬取的正文、LLM 生成的结果存入 Supabase 数据库。需处理去重逻辑（基于 `hn_id`）。 | P0 |
| B6 | **文章列表 API** | 提供 `GET /api/articles` 接口，支持分页，按时间或热度排序。 | P0 |
| B7 | **单篇对话 API (流式)** | 提供 `POST /api/chat/message` 接口。<br>1. **新对话**: 传入 `article_id`，`conversation_id=null`。系统创建新会话并流式返回。<br>2. **继续对话**: 传入 `conversation_id`。系统加载历史上下文并追加新消息。 | P0 |
| B8 | **全站 RAG 对话 API** | 提供 `POST /api/chat/global` 接口。基于 **LangChain** + **Vector Store** 实现。需异步对文章进行切分 (Chunking) 和向量化 (Embedding) 存入 `document_chunks` 表。检索时召回相关片段作为 Context。 | P1 |
| B9 | **对话历史 API** | 1. `GET /api/chat/sessions`: 获取当前用户在某文章下的会话列表。<br>2. `GET /api/chat/sessions/{id}/messages`: 获取指定会话的完整消息记录。 | P0 |

### 3.2 前端界面--暂定 (Frontend - React)

| ID | 页面/组件 | 详细描述 | 优先级 |
|:---|:---|:---|:---|
| F1 | **首页信息流** | 卡片式布局，展示：中文标题、一句话摘要、HN 分数、发布时间、原文链接。 | P0 |
| F2 | **文章详情页** | 展示 AI 生成的完整报告（使用 Markdown 渲染）。包括：背景、核心要点列表、潜在影响等。 | P0 |
| F3 | **加载状态** | 在数据加载或 AI 回复时展示 Skeleton Screen 或 Loading Spinner。 | P1 |
| F4 | **单篇对话组件** | 类似 ChatGPT 的聊天界面，集成在详情页中。支持用户输入、发送、接收流式打字机效果的回复。<br>**新增**: 左侧/顶部会话列表切换功能。 | P0 |
| F5 | **全局对话浮窗** | 在首页右下角或侧边栏提供全局对话入口，支持针对全站内容的自由提问（Global RAG）。 | P1 |

### 3.3 AI 提示词策略 (Prompt Strategy)

* **Summarizer Agent:**
    * **角色设定:** 资深架构师/Hacker News 中文社区首席观察员，采用“双层摘要法”与“金句保留”策略。
    * **输出格式:** 严格 JSON 格式。
    * **核心字段:** `topic` (领域), `title_cn` (中文标题), `summary` (深度摘要), `key_points` (关键思维模型), `takeaway` (犀利洞察), `score` (硬核评分), `tech_stack` (技术栈), `original_text_trans`/`url_content_trans` (原文精译)。
* **Chat Agent:** System Prompt 需包含：“你是一个技术助手，请仅依据以下提供的文章内容回答用户问题...”

---

## 4. 数据模型 (Database Schema - Supabase)

核心表结构设计 (`public.articles`)：

```sql
create table public.articles (
  id bigint generated by default as identity primary key,
  hn_id integer unique not null,          -- HN 原始 ID
  original_title text not null,           -- 英文原标题
  original_url text,                      -- 原文链接 (Ask HN 类型可能为空)
  score integer,                          -- HN 热度分数
  posted_at timestamptz,                  -- 发布时间
  raw_content text,                       -- 爬取的网页正文 或 HN text (用于 RAG)
  translated_title text,                  -- 中文标题
  summary text,                           -- 一句话摘要
  detailed_analysis jsonb,                -- 结构化分析 (JSON)
  created_at timestamptz default now()
);

-- 索引
create index articles_score_idx on public.articles (score desc);
create index articles_posted_at_idx on public.articles (posted_at desc);

-- 向量存储 (Global RAG 支持)
-- 需启用 pgvector 扩展: create extension vector;
create table public.document_chunks (
  id bigint generated by default as identity primary key,
  article_id bigint references public.articles(id) on delete cascade,
  content_chunk text,                     -- 切分后的文本片段
  embedding vector(1536),                 -- OpenAI Embedding (text-embedding-3-small)
  metadata jsonb,                         -- 额外元数据
  created_at timestamptz default now()
);
create index on public.document_chunks using hnsw (embedding vector_cosine_ops);

-- 对话持久化 (Chat Persistence)
create table public.conversations (
  id uuid default gen_random_uuid() primary key,
  user_id uuid not null,                  -- 关联 auth.users
  article_id bigint references public.articles(id), -- NULL for Global Chat
  title text,                             -- 会话标题
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);
create index conversations_user_article_idx on public.conversations(user_id, article_id);

create table public.messages (
  id bigint generated by default as identity primary key,
  conversation_id uuid references public.conversations(id) on delete cascade,
  role text not null check (role in ('user', 'assistant')),
  content text not null,
  created_at timestamptz default now()
);
create index messages_conversation_idx on public.messages(conversation_id, created_at);
```
